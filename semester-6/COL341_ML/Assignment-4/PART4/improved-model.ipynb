{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import confusion_matrix\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T11:28:48.115166Z","iopub.execute_input":"2023-04-29T11:28:48.115654Z","iopub.status.idle":"2023-04-29T11:28:48.126675Z","shell.execute_reply.started":"2023-04-29T11:28:48.115614Z","shell.execute_reply":"2023-04-29T11:28:48.125016Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n     transforms.RandomHorizontalFlip(p=0.5)\n    ])\n\nbatch_size = 4\nepochs = 20\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T11:28:48.129666Z","iopub.execute_input":"2023-04-29T11:28:48.130565Z","iopub.status.idle":"2023-04-29T11:28:50.059658Z","shell.execute_reply.started":"2023-04-29T11:28:48.130516Z","shell.execute_reply":"2023-04-29T11:28:50.058224Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.dropout1 = nn.Dropout2d(0.25)\n        \n        self.conv2 = nn.Conv2d(32, 64, 5)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.dropout2 = nn.Dropout2d(0.25)\n        \n        self.conv3 = nn.Conv2d(64, 64, 3)\n        self.bn3 = nn.BatchNorm2d(64)\n        \n        self.fc1 = nn.Linear(64 * 3 * 3, 64)\n        self.dropout3 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.dropout1(x)\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.dropout2(x)\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = self.dropout3(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x\n\nimport torch.optim as optim\nnet = Net()\nnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.0001)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T11:28:50.061775Z","iopub.execute_input":"2023-04-29T11:28:50.062287Z","iopub.status.idle":"2023-04-29T11:28:50.086521Z","shell.execute_reply.started":"2023-04-29T11:28:50.062231Z","shell.execute_reply":"2023-04-29T11:28:50.085049Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_loss = {}  # loss history\ny_loss['train'] = []\ny_loss['val'] = []\ny_acc = {}  # loss history\ny_acc['train'] = []\ny_acc['val'] = []\nx_epoch = []\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-29T11:28:50.089168Z","iopub.execute_input":"2023-04-29T11:28:50.089529Z","iopub.status.idle":"2023-04-29T11:28:50.098782Z","shell.execute_reply.started":"2023-04-29T11:28:50.089496Z","shell.execute_reply":"2023-04-29T11:28:50.096742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"total = 0 \nfor epoch in range(epochs):  # loop over the dataset multiple times\n    running_loss = 0.0\n    total_loss = 0.0\n    count = 0 \n    correct_pred = 0 \n    correct_pred_val = 0 \n    total_pred = 0 \n    total_pred_val = 0 \n    \n    for i, data in enumerate(trainloader, 0):\n        \n        count += 1\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device) , data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        _, predictions = torch.max(outputs, 1)\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred += 1\n            total_pred += 1\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n\n        curloss = loss.item()\n        running_loss += curloss\n        total_loss += curloss\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            total += 1 \n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n            \n            \n            with torch.no_grad():\n                correct = 0\n                loss_val = 0.0\n                countval = 0\n                for data_val in testloader:\n                    countval += 1\n                    inputs_val, labels_val = data_val[0].to(device) , data_val[1].to(device)\n                    # calculate outputs by running images through the network\n                    outputs_val = net(inputs_val)\n                    \n                    # the class with the highest energy is what we choose as prediction\n                    _, predicted = torch.max(outputs_val.data, 1)\n                    for label, prediction in zip(labels_val, predicted):\n                        if label == prediction:\n                            correct_pred_val += 1\n                        total_pred_val += 1\n                    loss = criterion(outputs, labels)\n                    loss_val += loss.item()\n                    if countval == 2000:\n                        break\n            loss_val /= countval\n            y_loss['val'].append(loss_val)\n            y_loss['train'].append(total_loss/count)\n            y_acc['train'].append(correct_pred / total_pred )\n            y_acc['val'].append(correct_pred_val/total_pred_val)\n            \n    x_epoch.append(total)\n    # since we're not training, we don't need to calculate the gradients for our outputs\n    \n    \nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T11:28:50.101203Z","iopub.execute_input":"2023-04-29T11:28:50.101715Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[1,  2000] loss: 2.250\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define your data\nx = [i for i in range(1,total+1)]\n\n# Set the figure size\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the data on the axis\nax.plot(x, y_loss['train'] , label='training-loss')\nax.plot(x, y_loss['val'] , label='validation-loss')\n\nfor i in x_epoch:\n    ax.axvline(i, color='gray', linestyle='--')\n\nax.legend()\nax.set_xlabel('epochs')\nax.set_ylabel('loss')\nax.set_title('Training and Validation Loss over Epochs')\n\n# Show the graph\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define your data\nx = [i for i in range(1,total+1)]\n\n\n# Set the figure size\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the data on the axis\nax.plot(x, y_acc['train'] , label='training-accuracy')\nax.plot(x, y_acc['val'] , label='validation-accuracy')\n\nfor i in x_epoch:\n    ax.axvline(i, color='gray', linestyle='--')\n\nax.legend()\nax.set_xlabel('epochs')\nax.set_ylabel('Accuracy')\nax.set_title('Training and Validation Accuracy over Epochs')\n# Show the graph\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data_check in testloader:\n        inputs_val, labels_val = data_check[0].to(device) , data_check[1].to(device)\n        \n        outputs = net(inputs_val)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels_val, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n            \n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"citation : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html (mentioned in the assignment)","metadata":{}}]}